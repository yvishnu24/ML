{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_data = load_iris()\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "print(iris_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris_data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(type(iris_data.data))\n",
    "print(iris_data.data.shape)\n",
    "print(iris_data.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.1 3.5 1.4 0.2]\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(iris_data.data[0])\n",
    "print(iris_data.target[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4) (105,) (45, 4) (45,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.30)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "logistic = linear_model.LogisticRegression(solver='lbfgs', max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression score:1.0\n"
     ]
    }
   ],
   "source": [
    "logistic = logistic.fit(X_train, y_train)\n",
    "score = logistic.score(X_test, y_test)\n",
    "print('LogisticRegression score:{}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 1 0 0 2 2 1 2 2 1 1 1 1 0 0 2 2 0 2 0 1 1 2 1 1 2 2 0 0 2 1 0 0 2 0\n",
      " 2 2 1 2 2 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "ypred_test= logistic.predict(X_test)\n",
    "print(ypred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 1 0 0 2 2 1 2 2 1 1 1 1 0 0 2 2 0 2 0 1 1 2 1 1 2 2 0 0 2 1 0 0 2 0\n",
      " 2 2 1 2 2 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_test)):\n",
    "    if (y_test[i] != ypred_test[i]):\n",
    "        print(i, y_test[i], ypred_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes [0 1 2]\n",
      "Total feature weights (3, 4)\n",
      "Total Bias weights (3,)\n",
      "Total iterations [113]\n"
     ]
    }
   ],
   "source": [
    "print(\"classes\", logistic.classes_)\n",
    "print(\"Total feature weights\", logistic.coef_.shape)\n",
    "print(\"Total Bias weights\", logistic.intercept_.shape) \n",
    "print(\"Total iterations\", logistic.n_iter_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.27255909 -0.32824891 -1.32474702]\n",
      " [-4.59610432 -0.20095554 -1.76049263]]\n",
      "[[0.01394605 0.72018374 0.26587021]\n",
      " [0.01009107 0.8179488  0.17196013]]\n"
     ]
    }
   ],
   "source": [
    "ypred_logproba= logistic.predict_log_proba(X_test[0:2])\n",
    "print(ypred_logproba)\n",
    "ypred_proba= logistic.predict_proba(X_test[0:2])\n",
    "print(ypred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn with K =3 train score:0.9523809523809523\n",
      "Knn with K =3 test score:0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)\n",
    "train_score = neigh.score(X_train, y_train)\n",
    "test_score = neigh.score(X_test, y_test)\n",
    "print('Knn with K =3 train score:{}'.format(train_score))\n",
    "print('Knn with K =3 test score:{}'.format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.2       , 0.3       , 0.38729833],\n",
       "        [0.26457513, 0.31622777, 0.34641016],\n",
       "        [0.3       , 0.31622777, 0.4       ],\n",
       "        [0.2       , 0.24494897, 0.3       ],\n",
       "        [0.14142136, 0.14142136, 0.17320508],\n",
       "        [0.36055513, 0.37416574, 0.41231056],\n",
       "        [0.24494897, 0.36055513, 0.42426407],\n",
       "        [0.63245553, 0.67082039, 0.75498344],\n",
       "        [0.26457513, 0.31622777, 0.42426407],\n",
       "        [0.        , 0.26457513, 0.31622777],\n",
       "        [0.33166248, 0.36055513, 0.37416574],\n",
       "        [0.24494897, 0.31622777, 0.37416574],\n",
       "        [0.50990195, 0.51961524, 0.53851648],\n",
       "        [0.24494897, 0.26457513, 0.26457513],\n",
       "        [0.14142136, 0.3       , 0.34641016],\n",
       "        [0.14142136, 0.17320508, 0.26457513],\n",
       "        [0.2       , 0.2236068 , 0.2236068 ],\n",
       "        [0.17320508, 0.36055513, 0.37416574],\n",
       "        [0.26457513, 0.34641016, 0.37416574],\n",
       "        [0.14142136, 0.14142136, 0.14142136],\n",
       "        [0.41231056, 0.7       , 0.96953597],\n",
       "        [0.34641016, 0.34641016, 0.37416574],\n",
       "        [0.24494897, 0.33166248, 0.34641016],\n",
       "        [0.38729833, 0.38729833, 0.72111026],\n",
       "        [0.43588989, 0.54772256, 0.55677644],\n",
       "        [0.42426407, 0.43588989, 0.6164414 ],\n",
       "        [0.37416574, 0.42426407, 0.51961524],\n",
       "        [0.41231056, 0.92736185, 1.02469508],\n",
       "        [0.3       , 0.37416574, 0.38729833],\n",
       "        [0.26457513, 0.31622777, 0.31622777],\n",
       "        [0.1       , 0.14142136, 0.14142136],\n",
       "        [0.55677644, 0.6164414 , 0.6164414 ],\n",
       "        [0.14142136, 0.26457513, 0.43588989],\n",
       "        [0.14142136, 0.14142136, 0.2236068 ],\n",
       "        [0.24494897, 0.31622777, 0.34641016],\n",
       "        [0.2236068 , 0.34641016, 0.36055513],\n",
       "        [0.2236068 , 0.28284271, 0.3       ],\n",
       "        [0.24494897, 0.24494897, 0.33166248],\n",
       "        [0.54772256, 0.54772256, 0.80622577],\n",
       "        [0.26457513, 0.28284271, 0.3       ],\n",
       "        [0.3       , 0.31622777, 0.38729833],\n",
       "        [0.45825757, 0.46904158, 0.50990195],\n",
       "        [0.2236068 , 0.2236068 , 0.24494897],\n",
       "        [0.31622777, 0.34641016, 0.34641016],\n",
       "        [0.17320508, 0.2       , 0.2236068 ]]),\n",
       " array([[ 10,  99,  33],\n",
       "        [ 48,  18,  79],\n",
       "        [ 44,  16,  66],\n",
       "        [ 34,  90,  97],\n",
       "        [100,  27,  13],\n",
       "        [ 25,  31,   3],\n",
       "        [ 26,  96,  19],\n",
       "        [ 16,  44,  40],\n",
       "        [ 53,  99,  33],\n",
       "        [ 80,  83,  39],\n",
       "        [ 89,   5,  62],\n",
       "        [ 49,  18,  29],\n",
       "        [ 70,  54,  90],\n",
       "        [ 82,  54,  90],\n",
       "        [  8,  95,  63],\n",
       "        [ 13,  57,  41],\n",
       "        [ 13,  98,  27],\n",
       "        [ 96,  44,  66],\n",
       "        [ 44,  16,  66],\n",
       "        [ 77,  15,  12],\n",
       "        [ 14,  52,  93],\n",
       "        [ 25,  60,  88],\n",
       "        [  8,  74,  63],\n",
       "        [ 84,  24,  20],\n",
       "        [ 93,  40,  55],\n",
       "        [ 97,  90,  82],\n",
       "        [ 48,  32,  74],\n",
       "        [  9,  52,  93],\n",
       "        [ 51,  19,  72],\n",
       "        [103,   1,  35],\n",
       "        [ 13,  57,  27],\n",
       "        [ 36,  42,  75],\n",
       "        [ 97,  90,  34],\n",
       "        [  0, 103,   1],\n",
       "        [ 76,   1,  73],\n",
       "        [ 19,  37,  75],\n",
       "        [ 35,  98,  65],\n",
       "        [ 75,  58,  36],\n",
       "        [ 52,  14,  93],\n",
       "        [ 54,  82,  90],\n",
       "        [ 42,  36,  66],\n",
       "        [ 40,  93,  55],\n",
       "        [ 28,  27,  77],\n",
       "        [ 49,  29,  86],\n",
       "        [ 77,  46,  65]], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.kneighbors(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2       , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.38729833, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.3       ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31622777, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.26457513, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.34641016,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.31622777, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.3       ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4       , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.kneighbors_graph(X_test[0:3], mode='distance').toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn with K =3 train score:1.0\n",
      "Knn with K =3 test score:0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "neigh.fit(X_train, y_train)\n",
    "train_score = neigh.score(X_train, y_train)\n",
    "test_score = neigh.score(X_test, y_test)\n",
    "print('Knn with K =3 train score:{}'.format(train_score))\n",
    "print('Knn with K =3 test score:{}'.format(test_score))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn with K =3 train score:0.9428571428571428\n",
      "Knn with K =3 test score:0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3, metric = 'manhattan')\n",
    "neigh.fit(X_train, y_train)\n",
    "train_score = neigh.score(X_train, y_train)\n",
    "test_score = neigh.score(X_test, y_test)\n",
    "print('Knn with K =3 train score:{}'.format(train_score))\n",
    "print('Knn with K =3 test score:{}'.format(test_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  1 16]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = neigh.predict(X_test)\n",
    "y_true = y_test\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        13\n",
      "  versicolor       0.94      1.00      0.97        15\n",
      "   virginica       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, target_names=iris_data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercises\n",
    "# 1. Try KNeighborsClassifier() on breast_cancer data for teh follwoing parameetrs\n",
    "#    different K values\n",
    "#    different distance metrics (manhattan, euclidean etc.)\n",
    "#    weights of the neigbours (uniform, distance etc..)\n",
    "#    different data structures, bruteforce, kdtree, balltree\n",
    "#    diffeerent leaf node sizes\n",
    "#    print k neighbors graph\n",
    "#    draw plot - K vs test accuracy\n",
    "\n",
    "# 2. Try RadiusNeighborsClassifier() on wines dataset \n",
    "#    for various r params\n",
    "#    draw plot -  r vs test accuracy\n",
    "\n",
    "# 3. Try KNeighborsRegressor() on boston house prices dataset or Diabetes dataset\n",
    "#    different K values\n",
    "#    different distance metrics (manhattan, euclidean etc.)\n",
    "#    weights of the neigbours (uniform, distance etc..)\n",
    "#    different data structures, bruteforce, kdtree, balltree\n",
    "#    diffeerent leaf node sizes\n",
    "#    print k neighbors graph\n",
    "#    draw plot - K vs test accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
